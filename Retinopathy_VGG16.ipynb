{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Class Weights\n",
      "Splitting data into test/ train datasets\n",
      "Reshaping Data\n",
      "X_train Shape:  (85108, 256, 256, 3)\n",
      "X_test Shape:  (21278, 256, 256, 3)\n",
      "Normalizing Data\n",
      "y_train Shape:  (85108, 5)\n",
      "y_test Shape:  (21278, 5)\n",
      "Training Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 165,738,309\n",
      "Trainable params: 165,738,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 68086 samples, validate on 17022 samples\n",
      "Epoch 1/100\n",
      "68086/68086 [==============================] - 836s 12ms/step - loss: 1.0566 - acc: 0.5960 - val_loss: 0.9035 - val_acc: 0.6487\n",
      "Epoch 2/100\n",
      "68086/68086 [==============================] - 832s 12ms/step - loss: 0.8743 - acc: 0.6637 - val_loss: 0.8325 - val_acc: 0.6820\n",
      "Epoch 3/100\n",
      "68086/68086 [==============================] - 848s 12ms/step - loss: 0.8228 - acc: 0.6854 - val_loss: 0.8031 - val_acc: 0.6903\n",
      "Epoch 4/100\n",
      "68086/68086 [==============================] - 823s 12ms/step - loss: 0.7931 - acc: 0.6972 - val_loss: 0.7979 - val_acc: 0.6984\n",
      "Epoch 5/100\n",
      "68086/68086 [==============================] - 821s 12ms/step - loss: 0.7626 - acc: 0.7076 - val_loss: 0.7873 - val_acc: 0.6993\n",
      "Epoch 6/100\n",
      "68086/68086 [==============================] - 821s 12ms/step - loss: 0.7325 - acc: 0.7207 - val_loss: 0.7845 - val_acc: 0.6992\n",
      "Epoch 7/100\n",
      "48630/68086 [====================>.........] - ETA: 3:40 - loss: 0.7028 - acc: 0.7335"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f19a8a4fa3eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_filters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f19a8a4fa3eb>\u001b[0m in \u001b[0;36mcnn_model\u001b[0;34m(X_train, X_test, y_train, y_test, kernel_size, nb_filters, channels, nb_epoch, batch_size, nb_classes)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 callbacks=None)\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;31m#callbacks=[stop, tensor_board])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/DL/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.utils import class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "\n",
    "def split_data(X, y, test_data_size):\n",
    "    '''\n",
    "    Split data into test and training datasets.\n",
    "\n",
    "    INPUT\n",
    "        X: NumPy array of arrays\n",
    "        y: Pandas series, which are the labels for input array X\n",
    "        test_data_size: size of test/train split. Value from 0 to 1\n",
    "\n",
    "    OUPUT\n",
    "        Four arrays: X_train, X_test, y_train, and y_test\n",
    "    '''\n",
    "    return train_test_split(X, y, test_size=test_data_size, random_state=42)\n",
    "\n",
    "\n",
    "def reshape_data(arr, img_rows, img_cols, channels):\n",
    "    '''\n",
    "    Reshapes the data into format for CNN.\n",
    "\n",
    "    INPUT\n",
    "        arr: Array of NumPy arrays.\n",
    "        img_rows: Image height\n",
    "        img_cols: Image width\n",
    "        channels: Specify if the image is grayscale (1) or RGB (3)\n",
    "\n",
    "    OUTPUT\n",
    "        Reshaped array of NumPy arrays.\n",
    "    '''\n",
    "    return arr.reshape(arr.shape[0], img_rows, img_cols, channels)\n",
    "\n",
    "\n",
    "def cnn_model(X_train, X_test, y_train, y_test, kernel_size, nb_filters, channels, nb_epoch, batch_size, nb_classes):\n",
    "    '''\n",
    "    Define and run the Convolutional Neural Network\n",
    "\n",
    "    INPUT\n",
    "        X_train: Array of NumPy arrays\n",
    "        X_test: Array of NumPy arrays\n",
    "        y_train: Array of labels\n",
    "        y_test: Array of labels\n",
    "        kernel_size: Initial size of kernel\n",
    "        nb_filters: Initial number of filters\n",
    "        channels: Specify if the image is grayscale (1) or RGB (3)\n",
    "        nb_epoch: Number of epochs\n",
    "        batch_size: Batch size for the model\n",
    "        nb_classes: Number of classes for classification\n",
    "\n",
    "    OUTPUT\n",
    "        Fitted CNN model\n",
    "    '''\n",
    "\n",
    "    '''model = Sequential()\n",
    "\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1]),\n",
    "        padding='valid',\n",
    "        strides=4,\n",
    "        input_shape=(img_rows, img_cols, channels)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(nb_filters, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    kernel_size = (16,16)\n",
    "    model.add(Conv2D(64, (kernel_size[0], kernel_size[1])))\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    print(\"Model flattened out to: \", model.output_shape)\n",
    "\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model = Sequential([\n",
    "    Conv2D(64, (3, 3), input_shape=input_shape, padding='same',\n",
    "           activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dense(5, activation='softmax')])\n",
    "\n",
    "    print(model.summary())'''\n",
    "    \n",
    "    model_vgg16_conv = VGG16(include_top=False)\n",
    "    model_vgg16_conv.summary()\n",
    "    \n",
    "    #Create your own input format\n",
    "    keras_input = Input(shape=input_shape, name = 'image_input')\n",
    "    \n",
    "    #Use the generated model \n",
    "    output_vgg16_conv = model_vgg16_conv(keras_input)\n",
    "    \n",
    "    #Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(nb_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    #Create your own model \n",
    "    model = Model(inputs=keras_input, outputs=x)\n",
    "    print(model.summary())\n",
    "    \n",
    "    adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                    optimizer=adam,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    stop = EarlyStopping(monitor='val_acc',\n",
    "                            min_delta=0.0001,\n",
    "                            patience=2,\n",
    "                            verbose=0,\n",
    "                            mode='auto')\n",
    "\n",
    "\n",
    "    tensor_board = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "\n",
    "    history = model.fit(X_train,y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "                verbose=1,\n",
    "                validation_split=0.2,\n",
    "                class_weight=weights,\n",
    "                callbacks=None)\n",
    "\t\t#callbacks=[stop, tensor_board])\n",
    "\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def save_model(model, score, model_name):\n",
    "    '''\n",
    "    Saves Keras model to an h5 file, based on precision_score\n",
    "\n",
    "    INPUT\n",
    "        model: Keras model object to be saved\n",
    "        score: Score to determine if model should be saved.\n",
    "        model_name: name of model to be saved\n",
    "    '''\n",
    "\n",
    "   # if score >= 0.75:\n",
    "    print(\"Saving Model\")\n",
    "    model.save(\"../models/\" + model_name + \"_recall_\" + str(round(score,4)) + \".h5\")\n",
    "   # else:\n",
    "    #    print(\"Model Not Saved.  Score: \", score)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \n",
    "    # Specify GPU's to Use\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "\n",
    "    # Specify parameters before model is run.\n",
    "    batch_size = 32\n",
    "    nb_classes = 5\n",
    "    nb_epoch = 200\n",
    "\n",
    "    img_rows, img_cols = 256, 256\n",
    "    channels = 3\n",
    "    nb_filters = 32\n",
    "    kernel_size = (8,8)\n",
    "\n",
    "    # Import data\n",
    "    labels = pd.read_csv(\"../labels/trainLabels_master_256_v2.csv\")\n",
    "    X = np.load(\"../data/X_train_256_v2.npy\")\n",
    "    y = np.array(labels['level'])\n",
    "\n",
    "\n",
    "    # Class Weights (for imbalanced classes)\n",
    "    print(\"Computing Class Weights\")\n",
    "    weights = class_weight.compute_class_weight('balanced', np.unique(y), y)\n",
    "\n",
    "\n",
    "    print(\"Splitting data into test/ train datasets\")\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, 0.2)\n",
    "\n",
    "\n",
    "    print(\"Reshaping Data\")\n",
    "    X_train = reshape_data(X_train, img_rows, img_cols, channels)\n",
    "    X_test = reshape_data(X_test, img_rows, img_cols, channels)\n",
    "\n",
    "    print(\"X_train Shape: \", X_train.shape)\n",
    "    print(\"X_test Shape: \", X_test.shape)\n",
    "\n",
    "\n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "\n",
    "    print(\"Normalizing Data\")\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "\n",
    "    y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    print(\"y_train Shape: \", y_train.shape)\n",
    "    print(\"y_test Shape: \", y_test.shape)\n",
    "\n",
    "\n",
    "    print(\"Training Model\")\n",
    "\n",
    "\n",
    "    model = cnn_model(X_train, X_test, y_train, y_test, kernel_size, nb_filters, channels, nb_epoch, batch_size, nb_classes)\n",
    "\n",
    "\n",
    "    print(\"Predicting\")\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "    y_pred = [np.argmax(y) for y in y_pred]\n",
    "    y_test = [np.argmax(y) for y in y_test]\n",
    "\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "\n",
    "\n",
    "    save_model(model=model, score=recall, model_name=\"DR_Five_Classes\")\n",
    "\n",
    "\n",
    "    print(\"Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
